{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "import random as rd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Chaînes de Markov (et rappels de probabilités)\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "```\n",
    "pierre.coucheney@uvsq.fr\n",
    "```\n",
    "\n",
    "\n",
    "Références:\n",
    "* introduction aux probabilités: https://www.youtube.com/watch?v=OhYJrpmEfS4\n",
    "* Markov chains and mixing times: https://pages.uoregon.edu/dlevin/MARKOV/markovmixing.pdf\n",
    "* Cours de probabilités avancé: https://www.imo.universite-paris-saclay.fr/~jean-francois.le-gall/IPPA2.pdf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Un exemple simple?\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "On lance une pièce: si elle tombe sur Pile, on gagne 1 point sinon 0.\n",
    "\n",
    "\n",
    "Combien de points obtient-on **en moyenne** si  on lance 1, 2, 3, 4, n fois la pièce? \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Méthode 1: estimation par simulation\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def nb_points1(nb_lancer):\n",
    "    pt = 0\n",
    "    for _ in range(nb_lancer):\n",
    "        pt += rd.randint(0,1)\n",
    "    return pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "nb_xp = 10000\n",
    "nb_lancer = 2\n",
    "data = [nb_points1(nb_lancer) for _ in range(nb_xp)]\n",
    "print(\"l'estimation de la moyenne pour\", nb_lancer,\"lancers vaut\", sum(data)/nb_xp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Méthode 2: modélisation par une variable aléatoire et calcul de la loi\n",
    "\n",
    "### Rappel: loi de probabilité sur un ensemble discret\n",
    "--- \n",
    "\n",
    "Un ensemble discret des événements élémentaires (univers) $\\Omega$ étant donné:\n",
    "* (positivité) pour tout événement $A \\subseteq \\Omega$, $\\mathbb{P}[A] \\geq 0$\n",
    "* $\\mathbb{P}[\\Omega] = 1$\n",
    "* (additivité) pour toute suite dénombrables d'événements $(A_i)_{i \\in \\mathbb{N}}$ deux à deux disjoints \n",
    "$$\\mathbb{P}[\\cup_{i \\in \\mathbb{N}} A_i] = \\sum_{i \\in \\mathbb{N}} \\mathbb{P}[A_i]$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Loi des probabilités totales**: supposons que $\\{B_i, i \\in \\mathbb{N} \\}$ est une partition de $\\Omega$:\n",
    "\n",
    "$$\n",
    "\\begin{array}{ll}\n",
    "\\mathbb{P}[A] & = \\mathbb{P}[A \\cap \\cup_{i \\in \\mathbb{N}} B_i ]  \\\\\n",
    "& = \\mathbb{P}[\\cup_{i \\in \\mathbb{N}} A \\cap B_i ]  \\\\\n",
    "& = \\sum_{i \\in \\mathbb{N}} \\mathbb{P}[A \\cap B_i ]  \\\\\n",
    "& = \\sum_{i \\in \\mathbb{N}} \\mathbb{P}[A | B_i ] \\mathbb{P}[B_i ]   \\\\\n",
    "& \n",
    "\\end{array}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Variable aléatoire discrète\n",
    "\n",
    "---\n",
    "\n",
    "Fonction sur $\\Omega$ muni de la loi de probabilité $\\mathbb{P}$ à valeur dans un ensemble discret $E$.\n",
    "\n",
    "**Variable aléatoire entière**: si E est un sous-ensemble de $\\mathbb{N}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Loi d'une variable aléatoire $X$:** pour tout $e \\in E$, donnée de $\\mathbb{P}[X^{-1}(e)]$, noté $\\mathbb{P}[X=e]$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Si $X_1$ et $X_2$ sont deux variable aléatoires, on note\n",
    "$$\\mathbb{P}[X_1 = e_1, X_2=e_2] = \\mathbb{P}[X_1 = e_1 \\text{ \"et\" } X_2=e_2] = \\mathbb{P}[X_1^{-1}(e_1) \\cap X_2^{-1}(e_2)] $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Espérance d'une variable aléatoire discrète $X$, avec $E \\subset \\mathbb{R}$\n",
    "\n",
    "---\n",
    "\n",
    "**Formule générale**:\n",
    "$$ \\mathbb{E}[X] = \\sum_{e \\in E}  e \\cdot \\mathbb{P}[X=e]$$\n",
    "\n",
    "$$ \\mathbb{E}[f(X)] = \\sum_{e \\in E}  f(e) \\cdot \\mathbb{P}[X=e]$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Lien avec la moyenne empirique**: on génère $N$ valeurs selon la loi de $X$; soit $n_e$ le nombre de fois où on a obtenu la valeur $e$, la moyenne empirique vaut alors\n",
    "$$\\frac1N \\sum_{e \\in E}e \\cdot n_e  = \\sum_{e \\in E}e \\cdot \\frac{n_e}{N}  $$\n",
    "\n",
    "Or les fréquences $n_e / N$ \"tendent\" vers la probabilité $\\mathbb{P}[X=e]$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Méthode 3: utilisation de la linéarité de l'espérance\n",
    "\n",
    "---\n",
    "Pour tous réels $a$ et $b$, et toutes variables aléatoires discrètes $X_1$ et $X_2$,\n",
    "\n",
    "\n",
    "$$\\mathbb{E}[aX_1 + b X_2] = a \\mathbb{E}[X_1]+b \\mathbb{E}[X_2]$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* pas d'hypothèse d'indépendance entre $X_1$ et $X_2$\n",
    "* en général $\\mathbb{E}[f(X)] \\neq f(\\mathbb{E}[X])$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Retour sur l'exemple**: On note $X_i$ le gain obtenu au i-ème lancer, alors le gain total en $n$ lancers vaut\n",
    "\n",
    "$$S_n = X_1 + X_2+ \\dots X_n$$\n",
    "\n",
    "on obtient facilement\n",
    "\n",
    "$$\\mathbb{E}[S_n] = \\mathbb{E}[X_1] + \\mathbb{E}[X_2]+ \\dots \\mathbb{E}[X_n] = n \\mathbb{E}[X_1] = 0.5n$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Variance d'une variable aléatoire discrète\n",
    "\n",
    "---\n",
    "Espérance de la distance à la moyenne:\n",
    "$$\\text{Var}(X) = \\mathbb{E}[(X - \\mathbb{E}[X])^2] $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* opérateur non linéaire\n",
    "* toujours positif\n",
    "* $\\text{Var}(aX) = a^2\\text{Var}(X)$\n",
    "* si $X_1$ et $X_2$ sont indépendantes alors \n",
    "$$\\text{Var}(X_1 + X_2) = \\text{Var}(X_1) + \\text{Var}(X_2)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$X_1$ et $X_2$ sont **indépendantes** si pour toutes valeurs $e_1$ et $e_2$, \n",
    "$$\\mathbb{P}[X_1 = e_1, X_2 = e_2] =  \\mathbb{P}[X_1 = e_1]\\cdot \\mathbb{P}[ X_2 = e_2]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Loi  des grands nombres\n",
    "\n",
    "---\n",
    "\n",
    "Soit $(X_i)_{i \\in \\mathbb{N}}$ une suite de variables aléatoires réelles iid, c'est-à-dire\n",
    "* indépendantes deux à deux\n",
    "* identiquement distribuées (de même loi), et d'espérance finie\n",
    "et soit \n",
    "$$M_n = \\frac1n (X_1 + X_2 + \\dots + X_n)  $$\n",
    "la moyenne des $n$ premières valeurs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "On a:\n",
    "\n",
    "* $\\mathbb{E}[M_n] =  \\mathbb{E}[X_1]$\n",
    "* $\\text{Var}(M_n) = \\text{Var}[X_1] / n$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Résultat**: \n",
    "\n",
    "Alors $M_\\infty = \\lim_{n \\rightarrow \\infty} M_n$ est une variable aléatoire qui vaut $\\mathbb{E}[X_1]$ avec probabilité 1.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Contre exemple si une des hypothèses n'est pas satisfaite?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Justifie:\n",
    "* l'estimation par simulation converge vers l'espérance de la variable aléatoire\n",
    "* la fréquence d'apparition d'une valeur tend vers la probabilité d'obtenir la valeur\n",
    "* méthodes de Monte-Carlo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Etude expérimentale de la loi de $M_n$ dans le cas du lancer de pièce\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "nb_xp = 10\n",
    "nb_lancer = 10\n",
    "data = [nb_points1(nb_lancer)/nb_lancer for _ in range(nb_xp)]\n",
    "\n",
    "sns.histplot(data, stat=\"probability\").set(xlim=(0,1))\n",
    "print(\"la moyenne de Mn vaut:\", f\"{sum(data)/nb_xp:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Deuxième exemple\n",
    "\n",
    "---\n",
    "\n",
    "On a un dé et une pièce équilibrés.\n",
    "\n",
    "* quand on lance le dé on gagne 1 point\n",
    "    * si on fait 5 ou 6, au coup suivant on lance la pièce\n",
    "    * sinon on continue à lancer le dé\n",
    "* quand on lance la pièce on ne gagne rien\n",
    "    * si on fait Pile, au coup suivant on lance le dé\n",
    "    * sinon on continue à lancer la pièce\n",
    "\n",
    "Au premier coup on lance la pièce."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Question**: combien gagne-t'on de points en moyenne si on fait 1, 2, 3, $n$ lancers?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Méthode 1: simulation\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def nb_points2(nb_lancer):\n",
    "    pt = 0\n",
    "    lance_piece = True\n",
    "    for _ in range(nb_lancer):\n",
    "        if lance_piece:\n",
    "            if rd.randint(0,1) == 0:\n",
    "                lance_piece = False\n",
    "        else:\n",
    "            pt += 1\n",
    "            if rd.randint(1,6) > 4:\n",
    "                lance_piece = True\n",
    "    return pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "nb_xp = 100000\n",
    "nb_lancer = 2\n",
    "data = [nb_points2(nb_lancer) for _ in range(nb_xp)]\n",
    "\n",
    "print(\"Estimation de la moyenne:\", f\"{sum(data)/nb_xp:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Evolution du nombre moyen de points par lancer\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "nb_xp = 10000\n",
    "res = []\n",
    "for nb_lancer in range(1, 51):\n",
    "    data = [nb_points2(nb_lancer) for _ in range(nb_xp)]\n",
    "    res.append(sum(data)/nb_xp/nb_lancer)\n",
    "print(res)\n",
    "sns.scatterplot(data=res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Méthode 2: calcul de la loi\n",
    "\n",
    "---\n",
    "\n",
    "Possible mais fastidieux."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Méthode 3: linéarité de l'espérance\n",
    "\n",
    "---\n",
    "\n",
    "On note $X_i$ le gain obtenu au i-ème lancer, alors le gain total en $n$ lancers vaut\n",
    "\n",
    "$$S_n = X_1 + X_2+ \\dots X_n$$\n",
    "\n",
    "donc \n",
    "\n",
    "$$\\mathbb{E}[S_n] =\\mathbb{E}[X_1] + \\mathbb{E}[X_2]+ \\dots \\mathbb{E}[X_n]$$\n",
    "\n",
    "mais les variables $X_i$ ne sont pas identiquement distribuées.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Mais $\\mathbb{E}[X_i] = \\mathbb{P}[X_i = 1]$ et \n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{array}{ll}\n",
    "\\mathbb{P}[X_i = 1] & = \\mathbb{P}[X_i = 1, X_{i-1} = 0] + \\mathbb{P}[X_i = 1, X_{i-1} = 1] \\\\\n",
    "& = \\mathbb{P}[X_i = 1 | X_{i-1} = 0]\\mathbb{P}[X_{i-1} = 0] + \\mathbb{P}[X_i = 1 | X_{i-1} = 1]\\mathbb{P}[X_{i-1} = 1] \\\\\n",
    "& = \\frac12 \\mathbb{P}[X_{i-1} = 0] + \\frac23 \\mathbb{P}[X_{i-1} = 1] \\\\\n",
    "& = \\frac12 (1- \\mathbb{P}[X_{i-1} = 1]) + \\frac23 \\mathbb{P}[X_{i-1} = 1]\\\\\n",
    "& = \\frac12 + \\frac16 \\mathbb{P}[X_{i-1} = 1]\\\\\n",
    "\\end{array}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Sachant $\\mathbb{P}[X_{1} = 1] = 0$, on obtient la relation\n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{array}{l}\n",
    "u_{i+1} = \\frac12 + \\frac16 u_{i} \\text{ pour tout }i \\geq 0\\\\\n",
    "u_1 = 0 \\\\\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "où $u_i = \\mathbb{P}[X_{i} = 1]$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "On peut alors calculer pour tout $i \\geq 0$\n",
    "$$\\mathbb{E}[X_{i}] = \\frac35 \\left(1 - \\left(\\frac16\\right)^{i} \\right) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Loi des grands nombres?\n",
    "\n",
    "---\n",
    "\n",
    "On note $X_i$ le gain obtenu au i-ème lancer, alors la moyenne des gains par lancer vaut\n",
    "\n",
    "$$M_n = \\frac1n (X_1 + X_2+ \\dots X_n)$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "On déduit de ce qui précède que\n",
    "$$\\mathbb{E}[M_n] = \\frac35 (1 - o(n))$$\n",
    "Donc $\\mathbb{E}[M_\\infty] = \\frac35$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    " Est-ce que $M_\\infty$ vaut $\\frac35$ avec probabilité 1 comme avec la loi forte des grands nombres?\n",
    "\n",
    "**Problème**: les variables $X_i$ ne sont ni indépendantes, ni identiquement distribuées."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Mais la suite $(X_i)_{i \\in \\mathbb{N}}$ est une **chaîne de Markov**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Chaîne de Markov sur l'exemple $(X_n)_{n \\in \\mathbb{N}}$\n",
    "\n",
    "---\n",
    "\n",
    "Graphe de transition:\n",
    "\n",
    "<center><img src='fig/chaine_exemple1.png'\"></center> \n",
    "\n",
    "\n",
    "\n",
    "Matrice de transition:\n",
    "\n",
    "$$ P = \n",
    "\\begin{array}{l|ll}\n",
    " & 0 & 1 \\\\ \\hline\n",
    "0 & \\frac12 & \\frac12 \\\\ \n",
    "1 & \\frac13 & \\frac23  \\\\\n",
    "\\end{array}\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Loi de $X_n$**\n",
    "\n",
    "---\n",
    "\n",
    "On note $q_k(n) = \\mathbb{P}[X_n = k]$ pour $k \\in \\{0,1 \\}$:\n",
    "\n",
    "$$\n",
    "\\begin{array}{ll}\n",
    "q_0(n+1) & = \\frac12 q_0(n) + \\frac13 q_1(n)\\\\\n",
    "q_1(n+1) & = \\frac12 q_0(n) + \\frac23 q_1(n)\\\\\n",
    "\\end{array}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "En notant $q(n) = [q_0(n), q_1(n)]$ le vecteur en ligne:\n",
    "$$ q(n+1) = q(n) P $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Chaîne de Markov $(X_n)_{n \\in \\mathbb{N}}$: suite\n",
    "\n",
    "---\n",
    "$$ q(n+1) = q(n) P $$\n",
    "\n",
    "Si $q(n)$ converge vers un vecteur de probabilité $\\pi = [\\pi_0, \\pi_1]$ alors on doit avoir\n",
    "\n",
    "$$ \\pi = \\pi P $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Ce système linéaire s'écrit:\n",
    "\n",
    "$$\n",
    "\\begin{array}{ll}\n",
    "\\pi_0 & = \\frac12 \\pi_0 + \\frac13 \\pi_1\\\\\n",
    "\\pi_1 & = \\frac12 \\pi_0 + \\frac23 \\pi_1\\\\\n",
    "\\end{array}\n",
    "$$\n",
    "qui donne $\\pi_1 = \\frac32 \\pi_0$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Comme $\\pi$ est un vecteur de probabilité \n",
    "$$\\pi_0 + \\pi_1 = 1$$\n",
    "alors on obtient\n",
    "$$\\pi = \\left[ \\frac25 , \\frac35 \\right] $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Théorème ergodique** (généralisation de la loi des grands nombres): avec probabilité 1,\n",
    "\n",
    "$$ \\lim_n \\frac1n (X_1 + X_2+ \\dots X_n) = \\pi_1 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Chaîne de Markov en temps discret\n",
    "\n",
    "--- \n",
    "\n",
    "Suite infinie de variables aléatoires $(X_n)_{n \\in \\mathbb{N}}$ (processus stochastique) à valeur dans un **ensemble fini d'états** $E$ telle que pour tout $n \\in \\mathbb{N}$ et tout ensemble d'états $(i_0, i_1, \\dots, i_{n-1}, i, j)$\n",
    "\n",
    "$$ \\mathbb{P}[X_{n+1} = j| X_0=i_0, X_1=i_1, \\dots, X_n=i] =  \\mathbb{P}[X_{n+1} = j | X_n = i]$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Si cette quantité ne dépend pas de $n$, la chaîne de Markov est dite **homogène**, et on écrit\n",
    "$$P_{i,j} = \\mathbb{P}[X_{n+1} = j | X_n = i] $$\n",
    "et $P = (P_{i,j})_{(i,j) \\in E^2}$ est la **matrice de transition** de la chaîne de Markov.\n",
    "\n",
    "Dans la suite, toute chaîne est supposée homogène."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Graphe de transition d'une chaîne de Markov\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "* ensemble de sommets: ensemble d'états $E$\n",
    "* un arc (orienté) entre sommet $i$ et $j$ dans $E$ si et seulement si $P_{i,j} > 0$\n",
    "* boucles autorisées"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Matrice stochastique\n",
    "\n",
    "---\n",
    "\n",
    "Une matrice de transition est une matrice stochastique:\n",
    "* ses coefficients sont positifs\n",
    "$$\\forall i,j \\in E, P_{i,j} \\geq 0 $$\n",
    "* la somme des coefficients sur chaque ligne vaut 1\n",
    "$$ \\forall i \\in E, \\sum_{j \\in E}P_{i,j} = 1$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Exemple**:\n",
    "\n",
    "\n",
    "$$ \n",
    "\\begin{array}{l|ccc}\n",
    " & 1 & 2 & 3 \\\\ \\hline\n",
    "1 & 1/4 & 1/2 & 1/4  \\\\ \n",
    "2 & 1/3 & 1/3 & 1/3 \\\\\n",
    "3 & 1/10 & 0 & 9/10  \\\\\n",
    "\\end{array}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Exemple de chaîne de Markov\n",
    "\n",
    "---\n",
    "\n",
    "Dans un (mini) magasin il peut y avoir au plus $2$ clients. A chaque pas de temps, un nouveau client arrive avec probabilité $q$, et s'il y a au moins un client dans le magasin, il sort un client avec probabilité $p$. Si un client arrive et que le magasin est complet, il repart aussitôt même si un client sort au même moment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Graphe de transition**:\n",
    "\n",
    "<center><img src='fig/chaine_exemple2.png'\"></center> \n",
    "\n",
    "\n",
    "\n",
    "**Matrice de transition**:\n",
    "\n",
    "$$ \n",
    "\\begin{array}{l|ccc}\n",
    " & 0 & 1 & 2 \\\\ \\hline\n",
    "0 & 1-q & q & 0 \\\\ \n",
    "1 & p(1-q) & 1-p(1-q)-q(1-p) & q(1-p)  \\\\\n",
    "2 & 0 & p & 1-p  \\\\\n",
    "\\end{array}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Questions typiques\n",
    "\n",
    "---\n",
    "\n",
    "* fréquence de passage dans un état donné: proportion du temps où le magasin est vide? nombre moyen de clients dans le magasin?\n",
    "* loi de $X_n$ dans un futur \"proche\": probabilité que le magasin soit vide dans 5 pas de temps?\n",
    "* loi de $X_n$ dans un futur \"lointain\": probabilité que le magasin soit vide dans 100000 pas de temps?\n",
    "* temps moyen avant de quitter un état: si le magasin est vide, combien de temps en moyenne le restera-t'il?\n",
    "* temps moyen pour atteindre un état: si le magasin est vide, combien de temps en moyenne pour qu'il soit complet?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Probabilité d'une trajectoire finie\n",
    "\n",
    "---\n",
    "\n",
    "$$\\mathbb{P}[X_0 = i_0, X_1 = i_1, X_2=i_2, \\dots , X_{n-1} = i_{n-1}, X_n = i_n] = \\mathbb{P}[X_0 = i_0] \\,P_{i_0, i_1} \\, P_{i_1, i_2}\\dots P_{i_{n-1}, i_n} $$\n",
    "\n",
    "Preuve par récurrence sur $n$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Probabilités de transition en $n$ étapes\n",
    "\n",
    "---\n",
    "\n",
    "On note $P_{i,j}^{(n)}$ la probabilité de passer de $i$ à $j$ en $n$ étapes,\n",
    "\n",
    "$$P_{i,j}^{(n)} =  \\mathbb{P}[X_n = j | X_0 = i]$$\n",
    "\n",
    "et $P^{(n)}$ la matrice associée."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Résultat**:\n",
    "$$P^{(n)} = P^n $$\n",
    "\n",
    "Preuve par récurrence sur $n$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Loi de $X_n$\n",
    "\n",
    "---\n",
    "\n",
    "On note $\\mu_n$ la loi de $X_n$, c'est-à-dire\n",
    "$$\\mu_n(i) = \\mathbb{P}[X_n = i] $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Résultat**:\n",
    "$$\\mu_n = \\mu_0 P^n $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Preuve**:\n",
    "$$\n",
    "\\begin{array}{ll}\n",
    "\\mathbb{P}[X_n = j] & = \\sum_{i \\in E}\\mathbb{P}[X_n = j, X_0 = i]\\\\\n",
    "& = \\sum_{i \\in E}\\mathbb{P}[X_n = j | X_0 = i]\\mathbb{P}[ X_0 = i]\\\\\n",
    "& = \\sum_{i \\in E} P^n_{i,j} \\, \\mu_0(i)\\\\\n",
    "& = (\\mu_0 P^n)_j\\\\\n",
    "\\end{array}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Conclusion**: la loi de $X_n$ est calculable pour des \"petites\" valeurs de $n$ en calculant $P^n$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Probabilité stationnaire\n",
    "\n",
    "---\n",
    "\n",
    "Supposons qu'il existe un vecteur de probabilité $\\pi$ sur $E$ tel que\n",
    "$$ \\pi = \\pi P $$\n",
    "\n",
    "Si $\\mu_0 = \\pi$, alors $\\mu_n = \\pi$ pour tout $n \\geq 0$.\n",
    "\n",
    "$\\pi$ est une **probabilité stationnaire** de la chaîne de Markov.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Propriétés (admises)**: \n",
    "* si $E$ est fini, alors il existe toujours une probabilité stationnaire.\n",
    "* de plus, si le graphe de la chaîne est **fortement connexe**, alors la probabilité stationnaire est **unique** et strictement positive; on dit que la chaîne de Markov est **irréductible**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Méthode générique pour calculer $\\pi$**: résoudre le système linéaire $\\pi = \\pi P$.\n",
    "\n",
    "Le calcul peut être simplifié dans certains cas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Interprétation en terme de flot\n",
    "\n",
    "---\n",
    "\n",
    "$$\n",
    "\\begin{array}{ll}\n",
    "& \\pi = \\pi P \\\\\n",
    "\\Leftrightarrow & \\forall i \\in E, \\pi(i) = \\sum_{j \\in E} \\pi(j)P_{j,i}\\\\\n",
    "\\Leftrightarrow & \\forall i \\in E, \\pi(i)\\sum_{k \\in E} P_{i,k} = \\sum_{j \\in E} \\pi(j)P_{j,i}\\\\\n",
    "\\Leftrightarrow & \\forall i \\in E, \\sum_{k \\in E}\\pi(i) P_{i,k} = \\sum_{j \\in E} \\pi(j)P_{j,i}\\\\\n",
    "\\end{array}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "En posant\n",
    "$$f(i,j) =  \\pi(i) P_{i,j}$$\n",
    "on obtient l'**équation de flot**, \"flot entrant = flot sortant\" sur chaque sommet du graphe de la chaîne de Markov\n",
    "$$ \\forall i \\in E, \\sum_{j: (j,i) \\in A} f(j,i) = \\sum_{k: (i,k) \\in A} f(i,k)  $$\n",
    "où $A$ est l'ensemble des arcs du graphe.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Illustration\n",
    "\n",
    "---\n",
    "\n",
    "<center><img src='fig/flot.png'\"></center> \n",
    "\n",
    "\n",
    "$$f(i,i) + f(j_1,i) + f(j_2, i) = f(i,i) + f(i,k_1) + f(i,k_2)+ f(i,k_3)$$\n",
    "\n",
    "Les boucles sur les états comptent comme flot entrant et flot sortant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Flot et coupe du graphe de la chaîne de Markov\n",
    "\n",
    "---\n",
    "\n",
    "**Résultat pratique pour calculer la distribution stationnaire**\n",
    "\n",
    "Si $f$ est un flot sur le graphe de la chaîne de Markov,alors pour toute partition des sommets en 2 ensembles $V_G$ et $V_D$ le flot de $V_G$ vers $V_D$ est égal au flot de $V_D$ vers $V_G$ (le bilan du flot sur toute coupe du graphe est nul).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Soit $(G,D)$ une partition de $E$,\n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{array}{ll}\n",
    "& f(G,E) = f(E,G) \\\\\n",
    "\\Leftrightarrow & f(G,G) + f(G,D) = f(G,G) + f(D,G) \\\\\n",
    "\\Leftrightarrow & f(G,D) = f(D,G) \\\\\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "**En français**: le flot de $G$ à $D$ est égal au flot de $D$ à $G$.\n",
    "\n",
    "<center><img src='fig/flot_cut.png'\"></center> \n",
    "    \n",
    "    \n",
    "$$ f(j_1, k_1) + f(j_1, k_2) =  f(k_1, j_2) + f(k_2, j_1)+ f(k_3, j_2) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Convergence de la probabilité $\\mu_n$ quand $E$ est fini\n",
    "---\n",
    "\n",
    "On rappelle que $\\pi$ est une probabilité stationnaire si \n",
    "$$ \\pi = \\pi P $$\n",
    "et la loi de probabilité de la chaîne de Markov au temps $n+1$ satisfait\n",
    "$$\\mu_{n+1} = \\mu_n P $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Si $\\mu_n$ converge vers une probabilité limite $\\mu_\\infty$ alors\n",
    "$$ \\mu_\\infty = \\mu_\\infty P $$\n",
    "Donc $\\mu_\\infty$ est une probabilité stationnaire.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Résultat (admis)**: si la chaîne de Markov est **irréductible et apériodique**, alors $\\mu_n$ converge vers l'unique probabilité stationnaire $\\pi$. En particulier cela ne dépend pas de $\\mu_0$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Apériodique**: le pgcd de la taille des circuits du graphe de la chaîne est 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Théorème ergodique (généralisation de la loi des grands nombres)\n",
    "\n",
    "---\n",
    "\n",
    "**Enoncé**: on suppose que la chaîne de Markov est irréductible avec $\\pi$ comme probabilité stationnaire, alors pour toute fonction réelle sur $E$, avec probabilité 1\n",
    "$$\\lim_{n \\rightarrow \\infty} \\frac1n \\sum_{k=0}^{n-1}f(X_k) = \\sum_{i \\in E} f(i) \\, \\pi(i) $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**En français**:\n",
    "* $\\displaystyle \\frac1n \\sum_{k=0}^{n-1}f(X_k)$: moyenne de $f$ sur $n$ pas de temps (moyenne temporelle)\n",
    "* $\\displaystyle \\sum_{i \\in E} f(i) \\pi(i)$: moyenne de $f$ sur les états selon la probabilité stationnaire (moyenne en espace)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Conséquences**: \n",
    "* la fréquence de passage par l'état $i$ tend vers $\\pi(i)$\n",
    "* le temps moyen de retour de l'état $i$ vers lui-même est $1/\\pi(i)$\n",
    "* si la chaîne est irréductible alors chaque état est visité une infinité de fois avec probabilité 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Théorème ergodique (suite)\n",
    "\n",
    "---\n",
    "\n",
    "$$\\lim_{n \\rightarrow \\infty} \\frac1n \\sum_{k=0}^{n-1}f(X_k) = \\sum_{i \\in E} f(i)\\, \\pi(i) $$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Dns l'exemple du magasin:\n",
    "* quelle est la proportion du temps où il n'y a aucun client?\n",
    "* combien de clients y a-t'il en moyenne?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Nature d'une chaîne de Markov, avec $E$ fini\n",
    "\n",
    "---\n",
    "\n",
    "* **irréductible**: graphe fortement connexe, probabilité stationnaire unique et le théorème ergodique s'applique\n",
    "* **apériodique**: pgcd de la taille des circuits vaut 1\n",
    "* **irréductible et apériodique**: convergence de la loi de $X_n$ vers l'unique probabilité stationnaire"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Temps d'atteinte d'un état\n",
    "\n",
    "---\n",
    "\n",
    "Soit une chaîne de Markov irréductible.\n",
    "\n",
    "On note $t_i(j)$ l'espérance du temps pour atteindre l'état $i$ depuis $j$.\n",
    "\n",
    "$$t_i(j) = \\mathbb{E}[T_i | X_0 = j] $$\n",
    "avec\n",
    "$$T_i = \\min \\{n \\geq 0 \\text{ tel que } X_n = i \\} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Résultat**:\n",
    "\n",
    "$$\n",
    "\\begin{array}{l}\n",
    "t_i(j) = 1 + \\sum_{k \\in E} P_{j,k} \\, t_i(k) \\text{ si }j\\neq i \\\\\n",
    "t_i(i) = 0\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "Preuve au tableau."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Calcul du temps d'atteinte par résolution du système linéaire (exemple au tableau)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Probabilité d'atteinte d'un état\n",
    "\n",
    "---\n",
    "\n",
    "Soit une chaîne de Markov irréductible.\n",
    "\n",
    "On note $p_{a,b}(i)$ la probabilité depuis l'état $i$ d'atteindre l'état $a$ avant l'état $b$.\n",
    "\n",
    "$$p_{a,b}(i) = \\mathbb{P}[T_a < T_b | X_0 = i] $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Résultat**:\n",
    "\n",
    "$$\n",
    "\\begin{array}{l}\n",
    "p_{a,b}(i) = \\sum_{j \\in E} P_{i,j} \\, p_{a,b}(j) \\text{ si } i \\neq a \\text{ et } i \\neq b \\\\\n",
    "p_{a,b}(a) = 1 \\\\\n",
    "p_{a,b}(b) = 0\n",
    "\\end{array}\n",
    "$$\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Diaporama",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "rise": {
   "scroll": true,
   "theme": "sky"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
